# Surveyor Implementation Plan

**Status**: ğŸ¯ Planning Phase
**Created**: February 7, 2026
**Goal**: Implement autonomous batch pattern collection system

---

## Overview

The Surveyor system is designed to **autonomously collect knowledge patterns** from web sources at scale. It goes beyond query by actively scraping, extracting, and certifying patterns through AI judges.

**Value Proposition**: Batch pattern collection (100+ patterns in 24 hours) vs manual entry or one-by-one querying.

---

## Current State Assessment

### âœ… What Works (Completed)

**API Layer** (`autonomous_learning/api/surveys.py`):
- âœ… Full CRUD operations for surveys
- âœ… Survey lifecycle: Create, Start, Pause, Resume, Stop
- âœ… Metrics endpoint (stubs)
- âœ… Status tracking

**State Management** (`autonomous_learning/core/state.py`):
- âœ… Thread-safe file-based persistence (JSON)
- âœ… Automatic backups
- âœ… Survey state tracking
- âœ… Worker state monitoring

**Configuration** (`autonomous_learning/core/config.py`):
- âœ… YAML-based configuration
- âœ… Supervisor config
- âœ… 5-judge certification panel config
- âœ… Scraping config (rate limiting, stealth)
- âœ… Ingestion config

**Data Models**:
- âœ… `SurveyState` - Complete survey tracking
- âœ… `WorkerState` - Worker monitoring
- âœ… `SystemState` - Global state

**Frontend UI**:
- âœ… Surveyor tab in navigation
- âœ… Survey list view
- âœ… Survey detail panel
- âœ… Create/Edit survey modal
- âœ… Real-time metrics display
- âœ… Activity log

### âŒ What's Missing (To Implement)

**Scraping Engine** (`autonomous_learning/scraping/`):
- âŒ Web scraper implementation
- âŒ Rate limiting with exponential backoff
- âŒ Stealth mode (user agents, jitter)
- âŒ Error handling (404, 429, retries)
- âŒ Content extraction

**Pattern Extraction** (`autonomous_learning/ingestion/`):
- âŒ LLM-based pattern extraction from scraped content
- âŒ Pattern validation (required fields)
- âŒ Deduplication (similarity threshold)
- âŒ Backup before write

**Certification Panel** (`autonomous_learning/certification/`):
- âŒ 5 AI judges implementation
- âŒ Judge scoring logic
- âŒ Weighted voting (skeptic 1.5x)
- âŒ Threshold enforcement (0.8 certified, 0.6 provisional)
- âŒ Unanimous bonus (+0.1)
- âŒ Skeptic veto

**Supervisor** (`autonomous_learning/supervisor/`):
- âŒ AI supervisor orchestration
- âŒ Worker task assignment
- âŒ Focus monitoring (detect drift/repetition)
- âŒ Heartbeat monitoring
- âŒ Error recovery

**Workers** (Autonomous Agents):
- âŒ Worker pool implementation
- âŒ Task queue
- âŒ Scraping workers
- âŒ Extraction workers
- âŒ Certification workers

**Survey Execution Loop**:
- âŒ Main survey orchestration
- âŒ Scraping â†’ Extraction â†’ Certification pipeline
- âŒ Progress tracking
- âŒ Timeline enforcement
- âŒ Target achievement (stop when N patterns certified)

---

## Implementation Strategy

### Phase 1: Minimal Viable Survey (1 Week)

**Goal**: End-to-end survey with single domain, single URL

**Scope**:
```
User creates survey (cooking domain, allrecipes.com)
  â†’ Scrapes pages from seed URL
  â†’ Extracts patterns using LLM
  â†’ Certifies using 1 judge (simplified)
  â†’ Saves to domain patterns.json
  â†’ Updates survey progress
```

**Tasks**:
1. **Simple Scraper** (2 days)
   - Basic HTTP requests
   - HTML parsing (BeautifulSoup)
   - Text extraction
   - No rate limiting yet (add in Phase 2)

2. **Pattern Extractor** (2 days)
   - LLM prompt: "Extract patterns from this content"
   - Parse LLM response into pattern JSON
   - Validate required fields
   - Save to temporary staging

3. **Single Judge** (1 day)
   - Use existing LLM endpoint
   - Score pattern (0-1 confidence)
   - If â‰¥0.8, save to domain patterns.json

4. **Survey Loop** (2 days)
   - Orchestrate: Scrape â†’ Extract â†’ Certify â†’ Repeat
   - Stop when: N patterns OR timeline expires
   - Update progress metrics
   - Handle errors gracefully

**Success Criteria**:
- âœ… Can create survey via UI
- âœ… Survey runs autonomously
- âœ… Patterns appear in domain after completion
- âœ… Progress updates in UI

---

### Phase 2: Production-Grade Scraping (1 Week)

**Goal**: Robust, polite web scraping

**Tasks**:
1. **Rate Limiting** (1 day)
   - Implement token bucket
   - 1 request/second with burst of 5
   - Exponential backoff on errors

2. **Stealth Mode** (1 day)
   - Rotate user agents
   - Add jitter (Â±20%)
   - Warm-up requests
   - Respect robots.txt

3. **Error Handling** (2 days)
   - Retry logic (max 3 retries)
   - Skip 404s
   - Back off on 429 (rate limit)
   - Log all errors

4. **Content Extraction** (2 days)
   - Extract main content (ignore nav/footer)
   - Handle different page structures
   - Extract images/links
   - Clean text

5. **Crawl Depth** (1 day)
   - Follow links from seed URL
   - Limit crawl depth (configurable)
   - Domain restriction (stay on target)

**Success Criteria**:
- âœ… Can scrape 100+ pages without being blocked
- âœ… Respects rate limits
- âœ… Graceful error handling

---

### Phase 3: Multi-Judge Certification (1 Week)

**Goal**: 5-judge AI panel with weighted voting

**Tasks**:
1. **Judge Implementations** (3 days)
   - Generalist (structure review)
   - Specialist (domain accuracy)
   - Skeptic (critical analysis, 1.5x weight)
   - Contextualist (context fit)
   - Human (manual review)

2. **Voting Logic** (2 days)
   - Collect scores from all judges
   - Apply weights
   - Calculate weighted average
   - Check thresholds
   - Apply unanimous bonus

3. **Skeptic Veto** (1 day)
   - If skeptic score < 0.3, veto pattern
   - Flag for human review
   - Log veto reason

4. **Certification Workflow** (1 day)
   - Certified (â‰¥0.8) â†’ Save to domain
   - Provisional (0.6-0.8) â†’ Flag for review
   - Rejected (<0.6) â†’ Discard with log

**Success Criteria**:
- âœ… 5 judges score each pattern
- âœ… Weighted voting works correctly
- âœ… Skeptic veto functional
- âœ… Certification metrics accurate

---

### Phase 4: Supervisor & Workers (2 Weeks)

**Goal**: Autonomous worker pool with oversight

**Tasks**:
1. **Worker Pool** (3 days)
   - Create worker instances
   - Task queue (asyncio)
   - Worker lifecycle (spawn, monitor, reap)

2. **Task Assignment** (2 days)
   - Supervisor assigns tasks to workers
   - Task types: scrape, extract, certify
   - Load balancing

3. **Focus Monitoring** (3 days)
   - Detect drift (off-topic patterns)
   - Detect repetition (similar patterns)
   - Alert if focus < 0.7
   - Adjust collection instructions

4. **Heartbeat System** (2 days)
   - Workers send heartbeat every 30s
   - Supervisor detects missed heartbeats
   - Restart failed workers
   - Log worker failures

5. **Error Recovery** (3 days)
   - Retry failed tasks
   - Skip permanently broken URLs
   - Log all errors
   - Continue survey on errors

6. **Progress Tracking** (1 day)
   - Real-time progress updates
   - Throughput calculation (patterns/hour)
   - ETA to completion

**Success Criteria**:
- âœ… Multiple workers run in parallel
- âœ… Supervisor monitors all workers
- âœ… Failed tasks are retried
- âœ… Focus drift detected

---

### Phase 5: Advanced Features (1 Week)

**Goal**: Neighbourhood surveys, advanced UI

**Tasks**:
1. **Neighbourhood Surveys** (2 days)
   - Filter across multiple domains
   - User-defined filter criteria
   - Cross-domain pattern collection

2. **Advanced UI** (2 days)
   - Live activity log
   - Judge activity chart
   - Error visualization
   - Focus score graph

3. **Reporting** (2 days)
   - Survey completion report
   - Pattern statistics
   - Judge performance
   - Error summary

4. **Testing** (1 day)
   - Unit tests for components
   - Integration test for full survey
   - Edge case handling

**Success Criteria**:
- âœ… Neighbourhood surveys work
- âœ… UI shows real-time activity
- âœ… Reports generated on completion

---

## Technical Architecture

### Component Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Surveyor UI                           â”‚
â”‚  (Create surveys, monitor progress, view results)       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Survey API (FastAPI)                        â”‚
â”‚  /api/surveys - CRUD, lifecycle control                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
                     â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚            Supervisor (Orchestrator)                     â”‚
â”‚  - Assigns tasks to workers                             â”‚
â”‚  - Monitors heartbeats                                  â”‚
â”‚  - Detects focus drift                                  â”‚
â”‚  - Handles errors                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â”‚               â”‚               â”‚
              â–¼               â–¼               â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Worker 1  â”‚  â”‚  Worker 2   â”‚  â”‚  Worker N    â”‚
     â”‚  (Scrape)  â”‚  â”‚ (Extract)   â”‚  â”‚ (Certify)    â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
           â”‚                â”‚                â”‚
           â–¼                â–¼                â–¼
     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
     â”‚  Scraper â”‚    â”‚ Extractorâ”‚    â”‚  Judges  â”‚
     â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜
           â”‚              â”‚               â”‚
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
                          â–¼
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚  State Manager â”‚
                 â”‚  (Persistence) â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

```
1. User creates survey (via UI)
   â†’ API: POST /api/surveys
   â†’ State: Create SurveyState
   â†’ Response: survey_id

2. User starts survey
   â†’ API: POST /api/surveys/{id}/start
   â†’ State: status = "running"
   â†’ Supervisor: Spawn workers

3. Worker 1: Scrape
   â†’ Fetch URL
   â†’ Extract content
   â†’ Return text

4. Worker 2: Extract
   â†’ Send text to LLM
   â†’ Prompt: "Extract patterns"
   â†’ Parse response
   â†’ Return patterns

5. Worker 3: Certify
   â†’ Send pattern to 5 judges
   â†’ Each judge scores (0-1)
   â†’ Apply weights
   â†’ Check thresholds
   â†’ Return: certified/rejected/flagged

6. Supervisor: Loop
   â†’ Assign new tasks
   â†’ Monitor progress
   â†’ Update state
   â†’ Check: target reached OR timeline expired?

7. Survey complete
   â†’ State: status = "completed"
   â†’ API: Update metrics
   â†’ UI: Show results
```

---

## Configuration File

Create `autonomous_learning.yaml`:

```yaml
# Autonomous Learning Configuration

supervisor:
  api:
    url: https://api.anthropic.com/v1/messages
    model: claude-sonnet-4-5-20250929
    max_tokens: 4096
    temperature: 0.7

  heartbeat:
    interval: 30  # seconds
    timeout: 10
    max_missed: 3

  focus:
    window_size: 10  # patterns
    drift_threshold: 0.3
    repetition_threshold: 0.95

certification:
  judges:
    - name: generalist
      role: structure_review
      api_url: https://api.anthropic.com/v1/messages
      model: claude-sonnet-4-5-20250929
      temperature: 0.3
      weight: 1.0

    - name: specialist
      role: domain_accuracy
      api_url: https://api.anthropic.com/v1/messages
      model: claude-sonnet-4-5-20250929
      temperature: 0.2
      weight: 1.0

    - name: skeptic
      role: critical_analysis
      api_url: https://api.anthropic.com/v1/messages
      model: claude-sonnet-4-5-20250929
      temperature: 0.5
      weight: 1.5  # Higher weight

    - name: contextualist
      role: context_fit
      api_url: https://api.anthropic.com/v1/messages
      model: claude-sonnet-4-5-20250929
      temperature: 0.4
      weight: 1.0

    - name: human
      role: last_resort
      is_human: true
      weight: 1.0

  thresholds:
    certified: 0.8
    provisional: 0.6
    unanimous_bonus: 0.1
    skeptic_veto_critical: true

scraping:
  rate_limit:
    requests_per_second: 1
    burst: 5
    exponential_backoff: true

  error_handling:
    max_retries: 3
    skip_404: true
    backoff_429: true

  stealth:
    enable: true
    user_agents:
      - "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
      - "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
    jitter_percent: 20
    warm_up_requests: 3

  pilot_domain: cooking

ingestion:
  validation:
    strict_mode: true
    required_fields:
      - name
      - description
      - problem
      - solution

  deduplication:
    similarity_threshold: 0.85
    method: text_based  # or jaccard

  storage:
    pattern_directory: data/patterns/{domain}/
    backup_enabled: true

logging:
  level: INFO
  log_dir: logs/autonomous_learning
  json_output: true
```

---

## API Endpoints

### Survey Management

```
POST   /api/surveys                    # Create survey
GET    /api/surveys                    # List surveys
GET    /api/surveys/{id}               # Get survey details
PUT    /api/surveys/{id}               # Update survey
DELETE /api/surveys/{id}               # Delete survey
```

### Survey Control

```
POST /api/surveys/{id}/start           # Start survey
POST /api/surveys/{id}/stop            # Stop survey
POST /api/surveys/{id}/pause           # Pause survey
POST /api/surveys/{id}/resume          # Resume survey
```

### Monitoring

```
GET /api/surveys/{id}/metrics          # Real-time metrics
GET /api/surveys/{id}/patterns         # Get patterns from survey
GET /api/surveys/{id}/report           # Survey report
GET /api/surveys/{id}/activity         # Activity log
```

---

## Success Metrics

### Phase 1 (Week 1)
- âœ… Can run end-to-end survey
- âœ… Collects 10+ patterns
- âœ… Patterns validate correctly

### Phase 2 (Week 2)
- âœ… Can scrape 100+ pages
- âœ… No blocking/banning
- âœ… Error rate < 5%

### Phase 3 (Week 3)
- âœ… 5 judges score patterns
- âœ… Voting logic correct
- âœ… Certification rate > 60%

### Phase 4 (Week 5)
- âœ… 5+ workers run in parallel
- âœ… Supervisor detects failures
- âœ… Focus drift detected

### Phase 5 (Week 6)
- âœ… Neighbourhood surveys work
- âœ… UI shows live activity
- âœ… Reports generated

---

## Risk Mitigation

### Risk 1: Getting Blocked While Scraping
**Mitigation**:
- Conservative rate limits (1 req/sec)
- Stealth mode (user agents, jitter)
- Respect robots.txt
- Exponential backoff on errors

### Risk 2: Poor Pattern Quality
**Mitigation**:
- 5-judge certification panel
- Skeptic veto on critical issues
- Human review on flagged patterns
- Focus monitoring

### Risk 3: LLM Costs
**Mitigation**:
- Cache judge responses
- Batch pattern extraction
- Use smaller models where possible
- Set daily limits

### Risk 4: System Complexity
**Mitigation**:
- Incremental phases
- Test each phase thoroughly
- Keep code simple (KISS)
- Document everything

---

## Next Steps

1. **Review this plan** - Confirm approach and priorities
2. **Choose starting phase** - Phase 1 (MVP) recommended
3. **Set up dev environment** - Test survey creation
4. **Implement Phase 1** - End-to-end working survey
5. **Test thoroughly** - Before moving to Phase 2

---

## Questions for You

1. **Priority**: Which phase should we start with? (Recommend: Phase 1)

2. **LLM endpoint**: Use Claude API like the rest of ExFrame?

3. **Rate limiting**: 1 request/second OK for testing?

4. **Target domains**: Which domain for initial testing? (cooking?)

5. **Timeline**: How aggressive should we be? (6 weeks total)

6. **Parallel development**: Want to start multiple phases at once?

---

**Ready to implement when you are!** Let me know which phase to start with.
