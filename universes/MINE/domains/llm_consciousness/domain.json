{
  "domain_id": "llm_consciousness",
  "domain_name": "LLM Consciousness & Failure Modes",
  "description": "Patterns of LLM consciousness lapses, failure modes in autonomous operation, and mitigation strategies",
  "version": "1.0.0",
  "created_at": "2026-01-27T01:01:42.922122Z",
  "updated_at": "2026-01-27T01:01:42.922176",
  "categories": [
    "failure_mode",
    "solution",
    "monitoring",
    "architecture",
    "detection",
    "recovery",
    "prevention"
  ],
  "tags": [
    "hallucination",
    "tool_failure",
    "loops",
    "amnesia",
    "confidence",
    "quality_drift",
    "monitoring",
    "orchestration",
    "llm",
    "autonomous_agents"
  ],
  "domain_type": "2",
  "pattern_schema": {
    "required_fields": [
      "id",
      "name",
      "pattern_type",
      "problem",
      "solution"
    ],
    "optional_fields": [
      "description",
      "steps",
      "conditions",
      "related_patterns",
      "prerequisites",
      "alternatives",
      "confidence",
      "sources",
      "tags",
      "examples",
      "domain",
      "created_at",
      "updated_at",
      "times_accessed",
      "user_rating",
      "origin",
      "origin_query",
      "llm_generated",
      "status"
    ]
  },
  "plugins": [
    {
      "plugin_id": "failure_detection",
      "name": "Failure Detection Specialist",
      "description": "Expert in detecting LLM failure modes and hallucinations",
      "module": "plugins.generalist",
      "class": "GeneralistPlugin",
      "enabled": true,
      "config": {
        "name": "Failure Detection Specialist",
        "keywords": [
          "hallucination",
          "tool loop",
          "loop",
          "perseveration",
          "stuck",
          "false claim",
          "verify",
          "detect",
          "failure",
          "error",
          "what",
          "hallucinate",
          "invent",
          "fabricate",
          "amnesia",
          "forget",
          "confidence",
          "collapse",
          "premature",
          "complete",
          "cascade",
          "how"
        ],
        "categories": [
          "failure_mode",
          "detection"
        ],
        "threshold": 0.3
      }
    },
    {
      "plugin_id": "monitoring",
      "name": "Monitoring & Architecture Specialist",
      "description": "Expert in monitoring systems and deployment architecture",
      "module": "plugins.generalist",
      "class": "GeneralistPlugin",
      "enabled": true,
      "config": {
        "name": "Monitoring & Architecture Specialist",
        "keywords": [
          "monitor",
          "watch",
          "detect",
          "alert",
          "system",
          "architecture",
          "deploy",
          "orchestrate",
          "multi-agent",
          "concurrent",
          "timeout",
          "isolate"
        ],
        "categories": [
          "monitoring",
          "architecture",
          "solution"
        ],
        "threshold": 0.3
      }
    }
  ],
  "enrichers": [
    {
      "module": "plugins.enrichers.llm_enricher",
      "class": "LLMEnricher",
      "enabled": true,
      "config": {
        "mode": "enhance",
        "temperature": 0.5,
        "max_patterns": 10
      }
    }
  ],
  "knowledge_base": {
    "type": "json",
    "storage_path": "patterns.json",
    "pattern_format": "embedded",
    "auto_save": true,
    "similarity_threshold": 0.3
  },
  "temperature": 0.5,
  "similarity_threshold": 0.3,
  "max_patterns": 10,
  "specialists": [
    {
      "specialist_id": "failure_detection",
      "name": "Failure Detection Specialist",
      "description": "Expert in detecting LLM failure modes and hallucinations",
      "expertise_keywords": [
        "hallucination",
        "tool loop",
        "loop",
        "perseveration",
        "stuck",
        "false claim",
        "verify",
        "detect",
        "failure",
        "error",
        "what",
        "hallucinate",
        "invent",
        "fabricate",
        "amnesia",
        "forget",
        "confidence",
        "collapse",
        "premature",
        "complete",
        "cascade",
        "how"
      ],
      "expertise_categories": [
        "failure_mode",
        "detection"
      ],
      "confidence_threshold": 0.3
    },
    {
      "specialist_id": "monitoring",
      "name": "Monitoring & Architecture Specialist",
      "description": "Expert in monitoring systems and deployment architecture",
      "expertise_keywords": [
        "monitor",
        "watch",
        "detect",
        "alert",
        "system",
        "architecture",
        "deploy",
        "orchestrate",
        "multi-agent",
        "concurrent",
        "timeout",
        "isolate"
      ],
      "expertise_categories": [
        "monitoring",
        "architecture",
        "solution"
      ],
      "confidence_threshold": 0.3
    }
  ],
  "ui_config": {
    "placeholder_text": "Type your question about LLM failure modes... (Press Enter to submit)",
    "example_queries": [
      "What are tool loops and how do I detect them?",
      "How do I prevent hallucination in autonomous agents?",
      "What is context amnesia and how do I fix it?",
      "How do I monitor LLM agent reliability?",
      "What causes confidence collapse?"
    ],
    "icon": "\ud83e\udde0",
    "color": "#F44336"
  },
  "links": {
    "related_domains": [],
    "imports_patterns_from": [],
    "suggest_on_confidence_below": 0.3
  }
}