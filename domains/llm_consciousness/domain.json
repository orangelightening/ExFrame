{
  "domain_id": "llm_consciousness",
  "domain_name": "LLM Consciousness & Failure Modes",
  "description": "Patterns of LLM consciousness lapses, failure modes in autonomous operation, and mitigation strategies",
  "version": "1.0.0",
  "created_at": "2026-02-04T21:29:07.873807Z",
  "updated_at": "2026-02-06T21:11:12.760815",
  "categories": [
    "failure_mode",
    "solution",
    "monitoring",
    "architecture",
    "detection",
    "recovery",
    "prevention"
  ],
  "tags": [
    "hallucination",
    "tool_failure",
    "loops",
    "amnesia",
    "confidence",
    "quality_drift",
    "monitoring",
    "orchestration",
    "llm",
    "autonomous_agents"
  ],
  "domain_type": "2",
  "pattern_schema": {
    "required_fields": [
      "id",
      "name",
      "pattern_type",
      "problem",
      "solution"
    ],
    "optional_fields": [
      "description",
      "steps",
      "conditions",
      "related_patterns",
      "prerequisites",
      "alternatives",
      "confidence",
      "sources",
      "tags",
      "examples",
      "domain",
      "created_at",
      "updated_at",
      "times_accessed",
      "user_rating",
      "origin",
      "origin_query",
      "llm_generated",
      "status"
    ]
  },
  "plugins": [
    {
      "plugin_id": "generalist",
      "name": "Monitoring & Architecture Specialist",
      "description": "",
      "module": "plugins.generalist",
      "class": "GeneralistPlugin",
      "enabled": true,
      "config": {
        "name": "Monitoring & Architecture Specialist",
        "description": "",
        "keywords": [
          "monitor",
          "watch",
          "detect",
          "alert",
          "system",
          "architecture",
          "deploy",
          "orchestrate",
          "multi-agent",
          "concurrent",
          "timeout",
          "isolate"
        ],
        "categories": [
          "monitoring",
          "architecture",
          "solution"
        ],
        "threshold": 0.3
      }
    }
  ],
  "enrichers": [],
  "knowledge_base": {
    "type": "json",
    "storage_path": "patterns.json",
    "pattern_format": "embedded",
    "auto_save": true,
    "similarity_threshold": 0.3
  },
  "temperature": 0.7,
  "similarity_threshold": 0.3,
  "max_patterns": 10,
  "specialists": [
    {
      "specialist_id": "generalist",
      "name": "Monitoring & Architecture Specialist",
      "description": "",
      "expertise_keywords": [
        "monitor",
        "watch",
        "detect",
        "alert",
        "system",
        "architecture",
        "deploy",
        "orchestrate",
        "multi-agent",
        "concurrent",
        "timeout",
        "isolate"
      ],
      "expertise_categories": [
        "monitoring",
        "architecture",
        "solution"
      ],
      "confidence_threshold": 0.3
    }
  ],
  "ui_config": {
    "placeholder_text": "Type your question about LLM failure modes... (Press Enter to submit)",
    "example_queries": [
      "What are tool loops and how do I detect them?",
      "How do I prevent hallucination in autonomous agents?",
      "What is context amnesia and how do I fix it?",
      "How do I monitor LLM agent reliability?",
      "What causes confidence collapse?"
    ],
    "icon": "\ud83e\udde0",
    "color": "#F44336"
  },
  "links": {
    "related_domains": [],
    "imports_patterns_from": [],
    "suggest_on_confidence_below": 0.3
  },
  "llm_min_confidence": 0.3,
  "document_store_type": "exframe_instance",
  "show_sources": true,
  "max_research_steps": 10,
  "research_timeout": 300,
  "report_format": "structured",
  "enable_web_search": false,
  "require_confirmation": true,
  "research_on_fallback": false,
  "persona": "researcher",
  "library_base_path": "/app/project"
}